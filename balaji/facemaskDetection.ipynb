{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "import numpy as np \r\n",
    "import pandas as pd \r\n",
    "import os\r\n",
    "from tensorflow.keras.applications import MobileNetV2\r\n",
    "from tensorflow.keras.layers import AveragePooling2D\r\n",
    "from tensorflow.keras.layers import Dropout\r\n",
    "from tensorflow.keras.layers import Flatten\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "from tensorflow.keras.layers import Input\r\n",
    "from tensorflow.keras.models import Model\r\n",
    "# import cv2\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras import layers\r\n",
    "\r\n",
    "# example of loading the inception v3 model\r\n",
    "from tensorflow.keras.applications import MobileNetV2\r\n",
    "from tensorflow.keras.layers import Input\r\n",
    "\r\n",
    "# load model\r\n",
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\r\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)))\r\n",
    "# summarize the model\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "batch_size = 40\r\n",
    "img_height = 224\r\n",
    "img_width = 224\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "## loading training data\r\n",
    "training_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "    './dataset',\r\n",
    "    validation_split=0.2,\r\n",
    "    subset= \"training\",\r\n",
    "    seed=42,\r\n",
    "    image_size= (img_height, img_width),\r\n",
    "    batch_size=batch_size\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 3833 files belonging to 2 classes.\n",
      "Using 3067 files for training.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "class_names = training_ds.class_names"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "## Configuring dataset for performance\r\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
    "training_ds = training_ds.cache().prefetch(buffer_size=AUTOTUNE)\r\n",
    "testing_ds = testing_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "## lets define our CNN\r\n",
    "headModel = baseModel.output\r\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\r\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\r\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\r\n",
    "headModel = Dropout(0.5)(headModel)\r\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)\r\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "## lets train our CNN\r\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\r\n",
    "# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\r\n",
    "retVal = model.fit(training_ds, validation_data= testing_ds, epochs = 15)\r\n",
    "model.save('model.h5')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/15\n",
      "77/77 [==============================] - 22s 218ms/step - loss: 0.0906 - accuracy: 0.9700 - val_loss: 26.7773 - val_accuracy: 0.5248\n",
      "Epoch 2/15\n",
      "77/77 [==============================] - 14s 188ms/step - loss: 0.0402 - accuracy: 0.9892 - val_loss: 15.5578 - val_accuracy: 0.5352\n",
      "Epoch 3/15\n",
      "77/77 [==============================] - 15s 189ms/step - loss: 0.0296 - accuracy: 0.9899 - val_loss: 6.6874 - val_accuracy: 0.7206\n",
      "Epoch 4/15\n",
      "77/77 [==============================] - 14s 188ms/step - loss: 0.0405 - accuracy: 0.9866 - val_loss: 23.6205 - val_accuracy: 0.4961\n",
      "Epoch 5/15\n",
      "77/77 [==============================] - 15s 190ms/step - loss: 0.0197 - accuracy: 0.9961 - val_loss: 15.7667 - val_accuracy: 0.5836\n",
      "Epoch 6/15\n",
      "77/77 [==============================] - 15s 194ms/step - loss: 0.0475 - accuracy: 0.9860 - val_loss: 5.6349 - val_accuracy: 0.5614\n",
      "Epoch 7/15\n",
      "77/77 [==============================] - 24s 314ms/step - loss: 0.0287 - accuracy: 0.9912 - val_loss: 2.6629 - val_accuracy: 0.8446\n",
      "Epoch 8/15\n",
      "77/77 [==============================] - 16s 203ms/step - loss: 0.0362 - accuracy: 0.9918 - val_loss: 5.0647 - val_accuracy: 0.7755\n",
      "Epoch 9/15\n",
      "77/77 [==============================] - 16s 205ms/step - loss: 0.0154 - accuracy: 0.9964 - val_loss: 3.1333 - val_accuracy: 0.8551\n",
      "Epoch 10/15\n",
      "77/77 [==============================] - 16s 210ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 6.3112 - val_accuracy: 0.7415\n",
      "Epoch 11/15\n",
      "77/77 [==============================] - 16s 211ms/step - loss: 0.0074 - accuracy: 0.9971 - val_loss: 1.1101 - val_accuracy: 0.9386\n",
      "Epoch 12/15\n",
      "77/77 [==============================] - 16s 208ms/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 1.8175 - val_accuracy: 0.9191\n",
      "Epoch 13/15\n",
      "77/77 [==============================] - 16s 213ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.8076 - val_accuracy: 0.9621\n",
      "Epoch 14/15\n",
      "77/77 [==============================] - 17s 218ms/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 1.9881 - val_accuracy: 0.8916\n",
      "Epoch 15/15\n",
      "77/77 [==============================] - 16s 213ms/step - loss: 1.6355e-04 - accuracy: 1.0000 - val_loss: 0.9197 - val_accuracy: 0.9465\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\laimo\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('tf': conda)"
  },
  "interpreter": {
   "hash": "f25a34d828536eaea94bc98fa02bf2fcbf5af5b65bea44899cc5ad2220dc98c9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}